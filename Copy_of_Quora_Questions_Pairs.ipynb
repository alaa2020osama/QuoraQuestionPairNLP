{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alaa2020osama/QuoraQuestionPairNLP/blob/main/Copy_of_Quora_Questions_Pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qPKYjF5N1sp"
      },
      "source": [
        "# \"Quora Questions Pairs using BERT\"\n",
        "> \"Task: Identify wether two question have similar context/meaning or not\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDHKLvx7CU6U"
      },
      "source": [
        "### Quora Questions Pairs using BERT : Overview\n",
        "\n",
        "**Task: Identify wether two question have similar context/meaning or not**<br>\n",
        "[kaggle](https://www.kaggle.com/c/quora-question-pairs/overview)\n",
        "<br>\n",
        "I have tried this problem using three different approach\n",
        "\n",
        "\n",
        "1.   Using Naive Bayes Classifier\n",
        "2.   Using BERT\n",
        "3.   Using fine tuned BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## to save the model in a directory in google drive. ##\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/QuoraQuestionsPair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKsVGLLaEEZj",
        "outputId": "26884f9f-63b9-4a63-95e2-30d1d92db3ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/QuoraQuestionsPair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZlQy8-Hekb5q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "path = \"/content/drive/MyDrive/QuoraQuestionsPair\"\n",
        "##### run them once ######\n",
        "#nltk.download()\n",
        "#!unzip /content/drive/MyDrive/QuoraQuestionsPair/quora_question_pairs.zip\n",
        "#!unzip /content/train.csv.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "aeioUHrErnWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "K1JfbFe3koUP",
        "outputId": "a193e723-cb33-43a0-962b-f69e5f42d4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 404290\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6   6    13    14                                Should I buy tiago?   \n",
              "7   7    15    16                     How can I be a good geologist?   \n",
              "8   8    17    18                    When do you use シ instead of し?   \n",
              "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  \n",
              "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
              "6  What keeps childern active and far from phone ...             0  \n",
              "7          What should I do to be a great geologist?             1  \n",
              "8              When do you use \"&\" instead of \"and\"?             0  \n",
              "9  How do I hack Motorola DCX3400 for free internet?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06cdb2bc-f078-4340-b05d-d47752f183f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06cdb2bc-f078-4340-b05d-d47752f183f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06cdb2bc-f078-4340-b05d-d47752f183f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06cdb2bc-f078-4340-b05d-d47752f183f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#load Data\n",
        "train_path = path+\"/train.csv\"\n",
        "train = pd.read_csv(train_path)\n",
        "print(\"Total samples:\",len(train))\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPLogC5t22AY",
        "outputId": "57970375-8649-412e-e4f1-69906d4339ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id              0\n",
            "qid1            0\n",
            "qid2            0\n",
            "question1       1\n",
            "question2       2\n",
            "is_duplicate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(train.isnull().sum(axis=0)) #dropping null values\n",
        "train.dropna(axis=0,inplace=True) # do operations in place and return none\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9wDKyOFDlT"
      },
      "source": [
        "#### Text Preprocessing\n",
        "\n",
        "\n",
        "*   Remove stop words\n",
        "*   Lemmatize \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9r3xbLrm_RN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2524899-e65c-4791-b4aa-de0a0ae9ea92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "#preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "def preprocess(series):\n",
        "  \n",
        "    # 1- Remove characters other than alphabets & numerics\n",
        "    # 2- make it small (no capital letters)\n",
        "    # 3 - split the sentence into words into a list\n",
        "    words = re.sub(\"[^A-Za-z0-9]\",\" \",series).lower().split() \n",
        "\n",
        "    # lemmatize words: lemmatization considers the context and converts the word to its meaningful base form. i.e. 'caring' --> 'care'\n",
        "    lemm = WordNetLemmatizer()\n",
        "\n",
        "    # Remove stop words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”)\n",
        "    stpwords = stopwords.words('english')\n",
        "    \n",
        "    # take a word by word and check if it is in the stopwords or not. lemmatize the words that are not in the stop words.\n",
        "    lemmitized = [lemm.lemmatize(word) for word in words if word not in stpwords]\n",
        "    \n",
        "    # Back to sentence: by joining the words with spaces in between\n",
        "    sent = ' '.join(lemmitized)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## Clarification Example ##########\n",
        "import re\n",
        "\n",
        "series = \"Welcome @mna 123alaa.// //alaa\"\n",
        "words = re.sub(\"[^A-Za-z0-9]\",\" \",series)\n",
        "words = words.split()\n",
        "print(words)\n",
        "\n",
        "sent = ' '.join(words)\n",
        "print(sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RqTJ0JSuYiI",
        "outputId": "3cc006e5-2197-477d-9aaa-c7fa6a97d695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Welcome', 'mna', '123alaa', 'alaa']\n",
            "Welcome mna 123alaa alaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri99TQVMoHEg"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing: to have sentence lemmatized, and without any symbols or capital letters\n",
        "train['question1'] =train['question1'].apply(preprocess)\n",
        "train['question2'] =train['question2'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "yNu_DueBwY3i",
        "outputId": "c156ec4d-0cd6-40c1-9292-40dbbf2da362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2          step step guide invest share market india   \n",
              "1   1     3     4                    story kohinoor koh noor diamond   \n",
              "2   2     5     6       increase speed internet connection using vpn   \n",
              "3   3     7     8                              mentally lonely solve   \n",
              "4   4     9    10  one dissolve water quikly sugar salt methane c...   \n",
              "5   5    11    12    astrology capricorn sun cap moon cap rising say   \n",
              "6   6    13    14                                          buy tiago   \n",
              "7   7    15    16                                     good geologist   \n",
              "8   8    17    18                                        use instead   \n",
              "9   9    19    20    motorola company hack charter motorolla dcx3400   \n",
              "\n",
              "                                           question2  is_duplicate  \\\n",
              "0                step step guide invest share market             0   \n",
              "1  would happen indian government stole kohinoor ...             0   \n",
              "2               internet speed increased hacking dns             0   \n",
              "3       find remainder math 23 24 math divided 24 23             0   \n",
              "4                      fish would survive salt water             0   \n",
              "5  triple capricorn sun moon ascendant capricorn say             1   \n",
              "6          keep childern active far phone video game             0   \n",
              "7                                    great geologist             1   \n",
              "8                                        use instead             0   \n",
              "9                hack motorola dcx3400 free internet             0   \n",
              "\n",
              "                                             combine  \n",
              "0  step step guide invest share market india step...  \n",
              "1  story kohinoor koh noor diamond would happen i...  \n",
              "2  increase speed internet connection using vpn i...  \n",
              "3  mentally lonely solve find remainder math 23 2...  \n",
              "4  one dissolve water quikly sugar salt methane c...  \n",
              "5  astrology capricorn sun cap moon cap rising sa...  \n",
              "6  buy tiago keep childern active far phone video...  \n",
              "7                     good geologist great geologist  \n",
              "8                            use instead use instead  \n",
              "9  motorola company hack charter motorolla dcx340...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e912b5d4-6d3a-49cc-913c-77067d1768f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>step step guide invest share market india</td>\n",
              "      <td>step step guide invest share market</td>\n",
              "      <td>0</td>\n",
              "      <td>step step guide invest share market india step...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>story kohinoor koh noor diamond</td>\n",
              "      <td>would happen indian government stole kohinoor ...</td>\n",
              "      <td>0</td>\n",
              "      <td>story kohinoor koh noor diamond would happen i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>increase speed internet connection using vpn</td>\n",
              "      <td>internet speed increased hacking dns</td>\n",
              "      <td>0</td>\n",
              "      <td>increase speed internet connection using vpn i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>mentally lonely solve</td>\n",
              "      <td>find remainder math 23 24 math divided 24 23</td>\n",
              "      <td>0</td>\n",
              "      <td>mentally lonely solve find remainder math 23 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
              "      <td>fish would survive salt water</td>\n",
              "      <td>0</td>\n",
              "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>astrology capricorn sun cap moon cap rising say</td>\n",
              "      <td>triple capricorn sun moon ascendant capricorn say</td>\n",
              "      <td>1</td>\n",
              "      <td>astrology capricorn sun cap moon cap rising sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>buy tiago</td>\n",
              "      <td>keep childern active far phone video game</td>\n",
              "      <td>0</td>\n",
              "      <td>buy tiago keep childern active far phone video...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>good geologist</td>\n",
              "      <td>great geologist</td>\n",
              "      <td>1</td>\n",
              "      <td>good geologist great geologist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>use instead</td>\n",
              "      <td>use instead</td>\n",
              "      <td>0</td>\n",
              "      <td>use instead use instead</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>motorola company hack charter motorolla dcx3400</td>\n",
              "      <td>hack motorola dcx3400 free internet</td>\n",
              "      <td>0</td>\n",
              "      <td>motorola company hack charter motorolla dcx340...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e912b5d4-6d3a-49cc-913c-77067d1768f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e912b5d4-6d3a-49cc-913c-77067d1768f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e912b5d4-6d3a-49cc-913c-77067d1768f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# concatenate Question 1 & Question 2\n",
        "'''\n",
        "def concat(ser):\n",
        "    print(ser['question1'])\n",
        "    return 1\n",
        "'''\n",
        "\n",
        "train['combine'] = train.apply(lambda ser: ser['question1'] + \" \" + ser['question2'],axis=1) \n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30WPiRB9FlHI"
      },
      "source": [
        "#### Convert Words into Vector\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Term Frequency (TF)\n",
        "The number of times a word appears in a document divded by the total number of words in the document. Every document has its own term frequency.\n",
        "\n",
        "![1_HM0Vcdrx2RApOyjp_ZeW_Q.png](data:image/png;base64,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)\n",
        "\n",
        "Inverse Data Frequency (IDF)\n",
        "The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
        "\n",
        "![1_A5YGwFpcTd0YTCdgoiHFUw.png](data:image/png;base64,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)\n",
        "\n",
        "Lastly, the TF-IDF is simply the TF multiplied by IDF.\n",
        "\n",
        "![1_nSqHXwOIJ2fa_EFLTh5KYw.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfkAAACACAIAAACHjocOAAAVu0lEQVR42uyd/5GqytPG3bduAIMh4I0ADQE3AjQENAI1BDSCoyGIEQghqBEoITBkcN6q7bpdfAVx5JfD+nz+uHWPu7I64jM93c/0/PP3798eAACAX83/YQgAAABaDwAAAFoPAAAAWg8AAABaDwAAAFoPAPh1SCknk8lwONT/pQZBMBgMtttt18f8H9x2AICWhd627cvl8ufPH/1f7Xg8FkLM5/MkSZbLZXeH/Qv+egBAm0I/Go2iKFosFuv1uisvezAYdO4134EcDgCgbaF3Xbdbonk6nUzT3Gw23Q3tofUAgJawbTuKIsdxqqS/B4PBV4bJZFL8rCAIvh6gUjYwDON4PAohNptNR0N75HAAAG0wmUwOh4NlWefzucp1brdbkiRxHB8Oh91ux4/HcWwYRrHcJ0nied7lcun1eqZpLhYL84fBYKDyp4Mg+P7+7vV6x+NxPB537AP4CwAADeN5HgnO9Xqt65r7/d6yLJayxWKh8qw4jnu9nuM4Vd6IECKO4259BIjrAQDNcj6fR6NRr9fb7/dPky3qzGYz0zSjKKLoXgghpXz6LCllv99/uggoYDweh2FYfYHSMsjXAwCaZTqd9no913VrFPperxeGoW3bi8WC/pkkie/7T591Op0syyot9DRj9Xq9y+XSrTottB4A0CCz2SyKIiEEp3FqQUoZx/FwOBwMBpzJSafvi2eIKn/aMAyS+81mEwQBtB4A8OkEQUD6u9vtqoTSucE1S/ZqtWIdv91uTWs91ZnpIrRkgdYDAD4XKSVJoW3b9WZv7iR7MpkIIRRD+8vlUouFhjb9dmgzLbQeANAIq9UqSRKWxea0nooBKlofBEHaulOFwWBAf3Sz2TxdTEDrAQC/k9vtRrLrOI6ie/2li5PaZrW+uEJbSwKH4QrEfD6H1gMAPjSovxPE5oJ60n1+pOAv1qv1hmGQCygMQ/2LtPDXAwBqhg31juOo+CBfhUqjs9ks/aDv+1wpvV6v2cUEOevrVTy6Ju3C1TyTg7geANCloP5ReJ6u0G42m+yzyFlf7ysxDIPSR1EUNTGrQesBAJoSBEEYhg1l6nOT9UxxhbbeBA7Dm7kamtig9QAAHeGYmpW3haD+bj3R6/WyrTTDMGzCDj8YDBzHITenzl0ToPUAgNqQUlJQL4RoqBNkgdYbhsE/ugvtpZSXy6WhUw95VtM5tIfWAwBqgxW2oaD+aSqGMyp3UXZDCRyCzins9XqHw0HbCi20HgBQGxzYNqT1Bcn6O9m9C+0b1fp0swSVnjzQegBAh6HDQHq9nmVZTVRlFSWbs/Ztaj3PbYfDAVoPAPjNsLY21xFMRbLTSwqq0EopoyhqKFlPDIdD0zTJfKlnhRZaDwCoASklh7TkS2lI659OJIZh8AsgU1DTQf3du6aOx9B6AMAvhOw35MBpKIFzu936/b5Kb2QO7SnKbkfrH1mAoPUAgF+o9e9N4BDj8ZgyKlQubkfr2WOaJImGaRxoPQCgBjhx0WgCR12y08XSppP12dBewzQOtB4AUJXb7UYOnF6vR13P9NH6tAS3pvW8yoHWAwB+D1yVNU2z3rMGGWoarH7xdIW2fa2/XC7QegDAb4PD2NobSTJ8ytVLT2lZ69OZIt062kPrAQC1aX29qno+n33fX6/Xg8GAIuXhcLjdbhVllD3v7STreWVzNyaa8A9uU9AOvu97nhdFESmC53kNOfO6Am3wieM4iqIkSUzTrP0A7nZId4CpN1lv2/ZdLH+5XOjAvziOVfI5i8WiZc21bZs8l9ql7P8C0DxUKPvz5w/9kxpUXa/XTx4T7tJFuK7b0TeS9pzgVk8fpK7VC0MOBzwPP7fbrZSy9BXW6/Vut+ND4yaTCe9m/OSBXa/Xf//+PR6PXX8jp9PpLn3xyaRXNlW+NbUDrQfP7935fJ4+BeJV6Llsikh7NjC84/G4OUN6O7DnBB/o3SDwLAitB7pzPp8pw859Yl+Fjwfiqt1isTBN0/O8hs6y6Bx0OPUviOubM+F0iHQVQSvnJWqzoIjq/gqO4rkSu/4BY/tr4PIp4noeB4qQ6L+I60GXtL60v4Ku0JrBGbS/8ktrHAYkPQ7I4YCOLc8tyyq3GZLdeFjd/1biOIbW38F3O+J60A24yUnpqLz6sgBoTlrOul54qAseh1c3+kLrwXuonqzn2pT+OZwgCMgS+iq+7y+XS2j9S81qfjdpI4M+tktoPWgwKqcrCCH0V4EwDHe73avWIN/3p9OptsdJtwCHrqWdWr84rtcqjdNVrT+fz8Ph0DCMwWBQYOoIgsAwjOzWcynleDw2DEO3/kTvZTAYfKVgC02/3+cHn6ph+iJ0oydJkr6snqdxrtdrx3HCMFSXexJ6IURrJTgpJfWHUe8Jw08MgoCeeDf+t9uNrlnuu8BahgQOk65bpOsZ0Poyq2YKpqSUruuuVqtHck+98bL7M1erVRiGSZJQbw1A7Pf743/wVm/HcfjB0+n09BAGvojnefSI67rpK7TZiOrV+0pd7tNC30Jjn/P5PB6PbduO49i2bdM0L5fLYDCYzWbFWQIp5Ww2o9+3LKvf769Wq+FweD6fgyAYj8e8KPn+/i4xDbPWI67PzeFoVJ7tXLuJ6/VqmmYcx3e9OLK/yTOq4zhd6VmhYVuP/X5f8QrH47FDb5x2sdq2/bQDjBCilpY+1CyooB8OzZrcTeju1dJ8k/vEOI7FD/x9SbfiSb/H0+nkuu7dr6nAMaxlWfjW3CkPnYCoyavqntLZtp3WDm4glb1NudPIoy8JtP6p5OUObGtX0FPu6xX6p1pfIPT8jSB3bPZHZP7LfS7FntWnYY5hi2fHTwNaX09Qnw0rhBAFfQRzv5M0995dTQfqNSmXjrboO1xlfAo+mu7Kfe1CX6z1FK8UfwrX6zV3nDnWyX2pNENUF2jW+uzqGVpPHUE0eUkd65Gw2WzSx0jebjdKh+UeXc8mkNx0qmEYlL7U7T16nldXra/f75ebOao76zlT2dEds77vTyaTw+EwHo+5aNlyjp7bxt11P84Ww23bDsNwvV6n3Z9cpsp9qZZlhWFY/U7TykIOCuheP5y01rNRJP0gQ+buAq3p9/uPfkrnSFSpIgZBMBqNSngNJz+8d5CrO+u5yqfo13zjgCvKfftCfz6fn97D/DGFYeh53qtO/xqVGj4czefCjvlwtttt+stMFgIhRFYjOBYr+J5EUZT7Uyllv98fjUal90Esl8vv7+8qfYC7rvUv9T7UdsDZmTMYDFoWeqqKFwTmaWj1liRJbnea3FElDUJXg8+hw3upuN1ublD/VK2KA0khhOu6VYJE0zRzX1iHtN40zdIjwDtmFeN6bQfc933LsuhOI9Fv7VNQ74jLSfN0Toa3AeeeCUMP1jhi1T2XXzpR12jo46/vsAuFk5gFDoSCwuDxeEQ1qaDWV/FUvKfj3xXS9tyGrCaParO8JHp6BZb4u0oglWezL/vR4+8tQmoV7tT1XvQRmQ7H9QUJHJVkfRiGuRVdUD2Bw+Pf9ZZn2+12Pp+T6+bVXbVtwsHjXdKctl9FUZTechUEwXQ6dRzn6ba4T44763pT+pQxunpWCRtFcvWak/UFWnM4HPQ8MWO73da41240Gr1a6a2xMNvpVsYs9JSjz3XmNIq6TDxqSrNcLj3PGw6H2+12tVrRfUUOnNp3L8OQozld1XpWw1w14Z8+UqsgCLStSm02mxq13rKsclqfm6ynvfVPr8Aphe7G9XdCz7n7NuWe3DUU2RTXCR7d8BzQlGvhCcqRLobr0zqiqzmc4uOMn/be2+122aoUdQ6ZTCaKipb79NlsNhwOq6wYbrdbjUvRV9+IlPKRs973fcUJUrGVsSYDrij0PAitJXN44/HTIi1NrqZp3r3aFpqx6FiE1AmNrKhdr5jl7gks3p1/vV5zd5NyPxDqLVWiwkZPp8JXt5rAZDdbZtvgmKapuFlUsTCr54Cr7IxV6ZlTy75ZxT/06CMTQhQ0V6gF7JstcDdo1SOhq3E9JweykYuUkvdY5cYa8/mcWzAy1NKWshbRDy+9ntlstlgs0kmPXKOb/jw6J3o2mzmOo+g4VCnM6jngihumWovud7udECIMw4J1D61pHMfJJuts257P577vtxC3Il+fW7pADqcqw+GQgsfsMRGu6/7584ekKvvT9Xptmmb2K8rfW+q78FJZkrL/LA0kWx3dRphb/9hut6fTSTFPonjGrIYD/tLO2BrlviD7YRhGGIZCiOl0mrslKgiC1WplWVauoFNMM51O78zjdPDDZDLZbrf8eZWDYwLkcJDDabYPWtrYS8Y4WgufTieaUXkNm/5ptg8ar3/Jtv9SI9+7ZTKtuzuaw+GUAq09r9er67qWZan3qmQnX8EYajjglAh6talZxWROHMd8o5qmeTqdHmUdbdu+S8jEcUxDV2xs57qUSJEtDFRsEqdnG8G3J0If7f55j4v0F2x1sSyL7mDTNLNfBpoPTNO0bVtFUOibUD2D2elR9TzPNE0hhGVZryZ8C7pM6zzg9JZLdK90XbeczD3qaPZIu2n3n2ma1n8sFouCF0yT7mKxyP0g4jim82Ro9Er3Q02/C6j8XbjzqKAIrddlQq6yX5TKMp/cy5tSN4ra8eEDnlXhunr908CqFAbjOC5oc68yR75F67Mlt6erk/1+z3Gh4zjNqfC7xuR31mYbYrPZVGwSQhXCjjbyrQUqzCruSf7wAc/uYKirTyd5RlXaXhqGQXFoueJ2uoZfunVdCWjfLy/cn/Zxm81m0+nUdV35g2ma//77b8VaxdMCjF7nMiKWTwc46bTj9XotkWuj9KU+SbqWYbeZSnyKAW/0Tn4pC186jfP23DQHCgUFGwq0efHHNYaGDKl61jAQ1/+Pvy0dY5LdrVyYqe3x2fVC+zm/vr622y09Qm5X27ZV4lMMeKPLBXUbK8Xj5RwjaWftW87R5uVIgSGKml2zBLMnu6HN8zwOWm3Oh9b30lFJ+oaIoujOeDf+oWChej6fkyT5nAQOt1jhLw9lA7K5VAx4y7iue7lcFHcj0+dVfPpVwbzCM3T7Wk+dyYsNvhyI8H1CmR/P8xraHlHcwQU5nPdD9zovDO9KN1xbL7C40XdGn51yTcNfHlo+k3arF1ox4C0UyZ9aUelTqDKGrGjtb53lDFLB6+e7tD3Hy3+85CSGD6fVLKdt284P2cxjHMfmDwU3dMGJ/r8S6lRBakLj81LOFwPegllFCGHbdlbx4zimLYeWZVXcmsBZuNLGzYrxWfE9wEF9Oy8pfVyMPoZLaH3JO7v4rvqo0SAfG4lyQ0fmY8CrB7+u69q2bVmW/QP9T7E9/6UZhW0nb1m7FNwDbBZo6ObM/UbomTX5B5nNuqDcKGefP4Q3noT+mQNeAip7NHd9FtwkSaSUNR7v/hSVI4myNeQWyn4aHt6A2uzLzpNHhmJylXT3PHEMOCg9l2S1tQX4CIECrVdsr1379KPj4Q1Y4b6aTyDnOG+XSC8VP3m7LAb8k+EYtrVUiWKyngKFNpNLLK1Nd5N+FcT1ryUNhBC0RKWVGgULUsrpdGrbdjtH02HAMeC6wVHz02NVSiClXC6Xw+GQ2nPyGVu8hrjbXUF7PgiyPyZJkm7zWeJgHPVlaHZMNOFLt+PbdWY2m7FXlw7zTJIkjuMkSVzXfVfaGgMO3k4QBN/f3xRB19spYb1eU9Pm3W5Hmr5er/f7fRiGtPkrO+Wfz2daBV4uF0rxua7LdZ1+v9/czjs60Yx2UTXUgAE5HADAWy19/1GjBZZC46zplmxF9OcKnPV8el1rDcbZflqlnR9yOAAAfeGUfV3l2clkEoZh7jEsnufxX9HKhMOGSw3tYdB6AEANcGfTWrR+uVxS443s0XLUmIHdWQUJGSoecMmnaW63G58+2MLR89B6AMAb4PRFda0/n8/U7NpxnEdSTkXX4vqnyu8wUsqKNVvuCqVngyZoPQCgBgzD4DRORX8U75l4dLCBirOehVslgSOl7Pf7o9GoSmFZ5wQOtB4AUH9on5t4UQ/qaWUghHiUCVFJ1r+6f1UI4bpu6WyPlJL9pooH9UDrAQCdhDWOsxkl4HmiQDF5MniarFeM6w3DkFKmDb5Vgvo2u0RA6wEAbWMYBgfaWfNMCdEs1vFiEae4vrXCLE9R2jbtgNYDAGqD+xaUS+NIKdnK8kjKOVlfnBZXmQ/q4na70Z8zTVPbI9Kg9QCA2hiPx+SGDMOwRJ0zfXrfo3hcJVnPhdl2mk3yxFbllHxoPQCgS3A7e8WjKHMp0GhO1qdPrOQmOQQXZovjeinlbDabTCbD4bCK4RJaDwD4OCaTCZ1ASx75l+AdUo8OOme7Szqo932f26ASiq2MV6uV53m+7/f7/dLmGd/3Ke+0WCz0rMpC6wEAjcD1yfV6/dITWSv5vPJHEXQ6YN/tdndKrVKYXa/X7JmJfqjyZoUQuh+lgJ5NAIDaIbEu0TieKq65hwwfj0eeA/jY7jiOs3+Fg/rixmrVz0Jg15D+B9wjrgcA1A8F4EmSvGpapyx/1qHv+/58Ps82YNjv93eJGm4mXJD0l1Le7fwql2rnoH65XOr+kSAAAQA0AUltidCegmXbtulIsuv16rquZVn0T7J1UtNgivTp8WyszbG/yhKkSlCv2xFU+U2ncUcCAJqAzTAlDia8Xq+O45g/WJZ1p9p//vwxTVMIYVlWtl0+e/zv5oBcjsdj6XbzVEk2TbMTHwe0HgDQFJwYuV6vLa8nLMtS+WXK/5Q4X0XltFutQL4eANAUnudRhoRO5msHMlyqeCillGEY8mbX2+2m6LK/3W7kKPU8T9uNsndA6wEATWEYBiW1wzAs3SHnJbgwq1JrvavK7na7R17PO2gisW27AyVZaD0AoAXG4zFXU+s9dpyUfTAYfH19sduHDDy2batsa6KKAvfViaIovRf3Edvt9nK5CCG4NtsNkFIEADQNpcXLedgLYJnmK1OyXjGHTpMQlxZUigpccFY0+aA2CwD4IGjHUzlPztMppNfrHY9HFmJ1U00cx7ZtOz+oTA9xHJP3ppxv57188R4zAABojvP5TI0NjsdjXUdvb7fb+XxOF5RSjkYjIUTFY2OL81FhGNq2XfGQxbcArQcAtITv+1TVPJ1OddlXfN/3PI+6jzmO82oHHnUmk8nhcLAsq7m5BFoPAPhVci+EOJ1OKoVQTVgul5vNxjTN0+mkczPLAuDDAQC0x2Qy2e/3SZKMRiP2R2rOer3ebDa0R7ejQo+4HgDwBoIg+P7+Nk1Tf7mnl2pZVhiG3RV6aD0A4D3cbrckSfTfdCqljKKoK5tjofUAAPDRIF8PAADQegAAANB6AAAA0HoAAADQegAAANB6AAAA0HoAAADQegAAANB6AACA1gMAAIDWAwAAgNYDAACA1gMAAIDWAwAAgNYDAACA1gMAAIDWAwDAZ/D/AQAA//8AejuABq6/IAAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "LEI22SiXBdhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KipLu4QmoViN",
        "outputId": "2780581c-6580-4eb5-e99d-d8606167b6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404287, 50000)\n",
            "(384072, 50000) (20215, 50000)\n"
          ]
        }
      ],
      "source": [
        "# Word to Vectors using Tf-Idf: is to score the relative importance of words\n",
        "# max features: if you pass, say, 5 to max_features, that would mean creating a feature matrix out of the most 5 frequent words accross text documents.\n",
        "cv = TfidfVectorizer(max_features=50000) \n",
        "\n",
        "# Take combine questions data as X\n",
        "X = cv.fit_transform(train['combine'])\n",
        "y = np.array(train['is_duplicate'])\n",
        "print(X.shape)\n",
        "\n",
        "# Train - Test Spilt\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hILRi5S4AokT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "naive_model = MultinomialNB()#Training\n",
        "naive_model.fit(X_train,y_train)\n",
        "\n",
        "# save the model to disk\n",
        "filename = 'MultinomialNB_model.sav'\n",
        "pickle.dump(naive_model, open(filename, 'wb'))\n",
        "\n",
        "#Predictions\n",
        "y_pred_train = naive_model.predict(X_train)\n",
        "y_pred_test = naive_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkhT6SwUwHSt",
        "outputId": "34f39da3-7c0b-4b68-c1ea-7a7c248a9367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7519761919640068 0.739055157061588\n"
          ]
        }
      ],
      "source": [
        " \n",
        "accuracy_train = sum((y_pred_train == y_train).astype(int))/len(y_train)\n",
        "accuracy_test = sum((y_pred_test == y_test).astype(int))/len(y_test)\n",
        "print(accuracy_train,accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRRwz7I3JJRr"
      },
      "source": [
        "We got 74% Accuracy which is very bad for binary classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8caSnoaJR2A"
      },
      "source": [
        "### BERT\n",
        "I have used \"Semantic Similarity with BERT\" code to solve this problem.<br>\n",
        "reference : https://keras.io/examples/nlp/semantic_similarity_with_bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8JzKW4bBuT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66c1dd0-0ba0-4e35-ee80-40beb44f3994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/QuoraQuestionsPair\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==2.11.0 in /usr/local/lib/python3.7/dist-packages (2.11.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (0.0.53)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0) (0.1.96)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==2.11.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/QuoraQuestionsPair\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "!pip install transformers==2.11.0\n",
        "import transformers\n",
        "path = \"/content/drive/MyDrive/QuoraQuestionsPair\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz9AA6PaNLig"
      },
      "outputs": [],
      "source": [
        "max_length = 128  # Maximum length of input sentence to the model.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Labels in our dataset.\n",
        "#1 : Non Duplicate\n",
        "#0 : Duplicate\n",
        "labels = [1,0] \n",
        "\n",
        "df = pd.read_csv(path+\"/train.csv\")\n",
        "testdf = pd.read_csv(path+\"/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqCjQXp7KYeE"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5OjhdncStr-",
        "outputId": "f0757a11-11d4-44f5-888c-6c5ce35d54f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id              0\n",
            "qid1            0\n",
            "qid2            0\n",
            "question1       1\n",
            "question2       2\n",
            "is_duplicate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(df.isnull().sum(axis=0))# Droping Null values\n",
        "df.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "MyVkSGoNNaqY",
        "outputId": "2dca8703-6b02-4b2a-c654-14b2b734675e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id  qid1  qid2                                          question1  \\\n",
              "6    6    13    14                                Should I buy tiago?   \n",
              "14  14    29    30  What are the laws to change your status from a...   \n",
              "21  21    43    44              What's causing someone to be jealous?   \n",
              "24  24    49    50  What does it mean that every time I look at th...   \n",
              "26  26    53    54                           What is web application?   \n",
              "\n",
              "                                            question2  is_duplicate  \n",
              "6   What keeps childern active and far from phone ...             0  \n",
              "14  What are the laws to change your status from a...             0  \n",
              "21   What can I do to avoid being jealous of someone?             0  \n",
              "24   How many times a day do a clock’s hands overlap?             0  \n",
              "26             What is the web application framework?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a41e00c6-6780-4097-9b83-e717c496cdca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>What's causing someone to be jealous?</td>\n",
              "      <td>What can I do to avoid being jealous of someone?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>What does it mean that every time I look at th...</td>\n",
              "      <td>How many times a day do a clock’s hands overlap?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>What is web application?</td>\n",
              "      <td>What is the web application framework?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41e00c6-6780-4097-9b83-e717c496cdca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a41e00c6-6780-4097-9b83-e717c496cdca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a41e00c6-6780-4097-9b83-e717c496cdca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#create mask for train-test distribution\n",
        "mask = np.random.rand(len(df)) < 0.7 [0, 1,1,0,0,0,0]\n",
        "train_df = df[mask] #train\n",
        "not_train = df[~mask] #dev\n",
        "#val_df = not_train\n",
        "\n",
        "#create mask for val-test distribution\n",
        "mask = np.random.rand(len(not_train)) < 0.5\n",
        "test_df = not_train[mask]\n",
        "val_df = not_train[~mask]\n",
        "#test_df = testdf\n",
        "val_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HYhifpvPWR4",
        "outputId": "3e078e7b-234f-4d9a-b303-803cd1337396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train samples : 283148\n",
            "Total validation samples: 60731\n",
            "Total test samples: 60408\n"
          ]
        }
      ],
      "source": [
        "Should I buy tiago? What does it mean that every time I look at th.\n",
        "[1, 2, 3, 4, 0, 0 , 0 , 0,0,... ]128\n",
        "attention mask: [1,1,1,1,0,0,....]\n",
        "token type ids: [1,1,1,1,0,0,0,0,0,0.....]\n",
        " .\n",
        " [1,2,3,4,5,6,....]128\n",
        "\n",
        " padding\n",
        "# Shape of the data\n",
        "print(f\"Total train samples : {train_df.shape[0]}\")\n",
        "print(f\"Total validation samples: {val_df.shape[0]}\")\n",
        "print(f\"Total test samples: {test_df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4qgJk-OrNg",
        "outputId": "2306a5ae-5eab-4e4d-cfbb-4848eea2cfe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Target Distribution\n",
            "0    178701\n",
            "1    104447\n",
            "Name: is_duplicate, dtype: int64\n",
            "Validation Target Distribution\n",
            "0    38255\n",
            "1    22476\n",
            "Name: is_duplicate, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Target Distribution\")\n",
        "print(train_df.is_duplicate.value_counts())\n",
        "\n",
        "print(\"Validation Target Distribution\")\n",
        "print(val_df.is_duplicate.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4AU_fSSTp-W",
        "outputId": "4c2155d6-46a1-4f7c-a736-e89f5a7a0194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train.shape:(283148, 2)\n",
            "y_val.shape:(60731, 2)\n",
            "y_test.shape:(60408, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_train = tf.keras.utils.to_categorical(train_df.is_duplicate, num_classes=2)# One hot encoding representation\n",
        "print(f\"y_train.shape:{y_train.shape}\")\n",
        "\n",
        "y_val = tf.keras.utils.to_categorical(val_df.is_duplicate, num_classes=2)\n",
        "print(f\"y_val.shape:{y_val.shape}\")\n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(test_df.is_duplicate, num_classes=2)\n",
        "print(f\"y_test.shape:{y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_CjpwdrKSnG"
      },
      "source": [
        "#### Custom Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p83ejnitUOmx"
      },
      "outputs": [],
      "source": [
        "# Tokenization is a way of separating a piece of text into smaller units called tokens.\n",
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentence_pairs,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        \n",
        "        # Load our BERT Tokenizer to encode the text (get the features).\n",
        "        # We will use bert-base-uncased pretrained model which is for english language and not case sensitive\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "            \"bert-base-uncased\", do_lower_case=True\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentence_pairs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size] #:[0,1,2,3,4,5,6,7,8,9,,,,,32]# to take a range of numbers for each batch\n",
        "        sentence_pairs = self.sentence_pairs[indexes] # to load the batch itself\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentence_pairs.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length = max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### for illustrations #####\n",
        "import transformers\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "sample_txt = 'when was i last outside? I am stuck at home for 2 weeks.'\n",
        "tokens = tokenizer.tokenize(sample_txt) #:['when','was'...]\n",
        "\n",
        "encoded = tokenizer.encode_plus(\n",
        "    sample_txt,\n",
        "    add_special_tokens=True,\n",
        "    max_length = 32,\n",
        "    return_attention_mask=True,\n",
        "    return_token_type_ids=True,\n",
        "    pad_to_max_length=True,\n",
        "    return_tensors=\"tf\",\n",
        ")\n",
        "encoded.keys()\n",
        "\n",
        "# Convert batch of encoded features to numpy array.\n",
        "input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "print(input_ids)\n",
        "print(attention_masks)\n",
        "print(token_type_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFN6bBfu9hty",
        "outputId": "0d730b3f-b3f4-4543-98a9-f91be764155a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 101 2043 2001 1045 2197 2648 1029 1045 2572 5881 2012 2188 2005 1016\n",
            "  3134 1012  102    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7SenBveKsJm"
      },
      "source": [
        "#### Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-AaVCJnVZY4",
        "outputId": "eeb6169c-8a76-48df-8d33-e43d6132b012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f94fb8075d0>\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  ((None, 128, 768),   109482240   ['input_ids[0][0]',              \n",
            "                                 (None, 768))                     'attention_masks[0][0]',        \n",
            "                                                                  'token_type_ids[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 128, 128)    426496      ['tf_bert_model_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional_1[0][0]']        \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional_1[0][0]']        \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            514         ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,909,250\n",
            "Trainable params: 427,010\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model under a distribution strategy scope.\n",
        "# This strategy is typically used for training on one machine with multiple GPUs.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    \n",
        "    # Encoded token ids from BERT tokenizer.\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "    )\n",
        "    \n",
        "    # Attention masks indicates to the model which tokens should be attended to.\n",
        "    attention_masks = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "    )\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "    )\n",
        "    # Loading pretrained BERT model.\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    \n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
        "    bert_model.trainable = False\n",
        "    \n",
        "    # Indices can be obtained using BertTokenizer. \n",
        "    sequence_output, pooled_output = bert_model(\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "    )\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(sequence_output)\n",
        "    \n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
        "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n",
        "    model = tf.keras.models.Model(\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "    )\n",
        "\n",
        "    # To config the model with losses and metrics\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"acc\"],\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"Strategy: {strategy}\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGgQnzm5Kyu0"
      },
      "source": [
        "#### Create train and validation data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0e76ed6b10844d2c9743203915fcdd65",
            "e3e3215fe7b041058d4f001b383003a1",
            "0f54382bd8d84aa1a0e2b9efa389ce56",
            "90bfc3c14a404c32b4c6a42554eca1f3",
            "bc4713b3d01f4d58bda699c48c3a8fa0",
            "4e381e29a3c946aaa882ee3d4a6e5349",
            "9ae037a5a6414f2e9929490dcf161c80",
            "41a3e7cc36e3485db1095faeb532f84b",
            "8be0eca918d143ec8ee73fdf423439bc",
            "d9f9f25286df4e808897e7205fcada79",
            "07f2ef2cfc224efc8eaeafc5c35c5b69"
          ]
        },
        "id": "u0YYkAdWVzx9",
        "outputId": "40f8b844-9b18-4f01-de4e-fec02d59f8ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e76ed6b10844d2c9743203915fcdd65"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = BertSemanticDataGenerator(\n",
        "    train_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_data = BertSemanticDataGenerator(\n",
        "    val_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klXsKJVkK5ng"
      },
      "source": [
        "#### Train the model\n",
        "Training is done only for the top layers to perform \"feature extraction\", which will allow the model to use the representations of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtddz2yOYh7J",
        "outputId": "1ab2d1ca-891b-4ee9-a852-3198f8fd01a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "8840/8840 [==============================] - 2216s 248ms/step - loss: 0.3937 - acc: 0.8100 - val_loss: 0.3511 - val_acc: 0.8345\n",
            "Epoch 2/2\n",
            "8840/8840 [==============================] - 2196s 248ms/step - loss: 0.3439 - acc: 0.8404 - val_loss: 0.3191 - val_acc: 0.8547\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=epochs,\n",
        "     use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEbnhEX1CWRg"
      },
      "source": [
        "#### Fine Tuning (Optional)\n",
        "\n",
        "Now BERT model has knowledge of Language & Context now we can unfreeze the BERT pretrained weights & retrain using very low learning rate to solve actual NLP problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPYy3UMICQN_",
        "outputId": "278ecf50-6aa4-41e2-f679-4b32597a9396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  ((None, 128, 768),   109482240   ['input_ids[0][0]',              \n",
            "                                 (None, 768))                     'attention_masks[0][0]',        \n",
            "                                                                  'token_type_ids[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 128, 128)    426496      ['tf_bert_model_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional_1[0][0]']        \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 128)         0           ['bidirectional_1[0][0]']        \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 256)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 256)          0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            514         ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,909,250\n",
            "Trainable params: 109,909,250\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bert_model.trainable = True\n",
        "# Recompile the model to make the change effective.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-OHjA9aYwn7",
        "outputId": "39426b3e-66bd-4c4c-c369-00431948a191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "8840/8840 [==============================] - 4825s 544ms/step - loss: 0.2905 - accuracy: 0.8712 - val_loss: 0.2614 - val_accuracy: 0.8853\n",
            "Epoch 2/2\n",
            "8840/8840 [==============================] - 4790s 542ms/step - loss: 0.2173 - accuracy: 0.9088 - val_loss: 0.2409 - val_accuracy: 0.9017\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('BERTModel.h5')\n",
        "#print('Model Saved!')\n",
        "model.save_weights('gfgModelWeights')\n",
        "print('Model Saved!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GV5gbr9bgWr",
        "outputId": "ce9bcf82-fd27-4a56-ca6b-04b3020a2c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLjeRqvWMbyx"
      },
      "source": [
        "After Waiting of 4-5 hours now our model is trained!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sYaB-wCjDp"
      },
      "source": [
        "#### Evaluate on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "#savedModel=load_model('BERTModel.h5')\n",
        "#savedModel.summary()\n",
        "\n",
        "# load model\n",
        "savedModel = model.load_weights('gfgModelWeights')\n",
        "print('Model Loaded!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoHqfOUljXgg",
        "outputId": "b86009d0-0fbd-4178-b025-c5627bc80066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1jV1ZuOChKi"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_data = BertSemanticDataGenerator(\n",
        "    test_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "#model.evaluate(test_data, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS6T3PSpLp5k"
      },
      "source": [
        "We Got 90% Accuracy on Test Dataset which is far better than Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uUn9RU2DcfB"
      },
      "outputs": [],
      "source": [
        "def check_similarity(sentence1, sentence2):\n",
        "  sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "  test_data = BertSemanticDataGenerator(\n",
        "      sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "  )\n",
        "\n",
        "  proba = model.predict(test_data)[0]\n",
        "  idx = np.argmax(proba)\n",
        "  proba = f\"{proba[idx]: .2f}%\"\n",
        "  pred = labels[idx]\n",
        "  return pred, proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioYNFI58LfJL"
      },
      "source": [
        "#### Try the custom Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XTA9J9gxOPtR",
        "outputId": "d8df2e5a-4d6b-4561-ce88-c100541011d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can I get rid of pimples all over my face?\n",
            "What is the best way to get rid of acne?\n",
            "INFO:tensorflow:Error reported to Coordinator: Layer \"model_1\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 342, in run\n",
            "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n",
            "    return converted_call(f, args, kwargs, options=options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n",
            "    outputs = model.predict_step(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "    return self(x, training=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n",
            "    raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n",
            "ValueError: Layer \"model_1\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-440638d2ad49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_duplicate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcheck_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-99803c357f5d>\u001b[0m in \u001b[0;36mcheck_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m      5\u001b[0m   )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{proba[idx]: .2f}%\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n        raise value\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_1\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "ind = np.random.randint(0,500) \n",
        "#Duplicate Questions\n",
        "q1 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question1']\n",
        "q2 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question2']\n",
        "print(q1+\"\\n\"+q2)\n",
        "check_similarity(q1,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-NhfBIwGOZ2_",
        "outputId": "d60a1e60-de7e-4891-bb4b-e84a156c43f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the difference between a premier and authentic NHL jersey?\n",
            "What is the difference between the FA Cup and the Capital One Cup?\n",
            "INFO:tensorflow:Error reported to Coordinator: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 342, in run\n",
            "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n",
            "    return converted_call(f, args, kwargs, options=options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n",
            "    outputs = model.predict_step(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n",
            "    return self(x, training=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n",
            "    raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n",
            "ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bb271e9e01ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_duplicate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcheck_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-99803c357f5d>\u001b[0m in \u001b[0;36mcheck_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m      5\u001b[0m   )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{proba[idx]: .2f}%\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n        raise value\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'cond/Identity:0' shape=(None, None) dtype=int32>]\n"
          ]
        }
      ],
      "source": [
        "ind = np.random.randint(0,500)\n",
        "#Non-Duplicate Questions\n",
        "q1 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question1']\n",
        "q2 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question2']\n",
        "print(q1+\"\\n\"+q2)\n",
        "check_similarity(q1,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1rr6dvgSmVL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for illustration ###\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "text='check check fail'\n",
        "tokenizer = Tokenizer(num_words=50000)\n",
        "tokenizer.fit_on_texts([text])\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxD1_FWaLgmL",
        "outputId": "5bacf745-f762-464d-cff8-85d739453e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'check': 1, 'fail': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fbQnSHZrMi1c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Quora Questions Pairs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e76ed6b10844d2c9743203915fcdd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3e3215fe7b041058d4f001b383003a1",
              "IPY_MODEL_0f54382bd8d84aa1a0e2b9efa389ce56",
              "IPY_MODEL_90bfc3c14a404c32b4c6a42554eca1f3"
            ],
            "layout": "IPY_MODEL_bc4713b3d01f4d58bda699c48c3a8fa0"
          }
        },
        "e3e3215fe7b041058d4f001b383003a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e381e29a3c946aaa882ee3d4a6e5349",
            "placeholder": "​",
            "style": "IPY_MODEL_9ae037a5a6414f2e9929490dcf161c80",
            "value": "Downloading: 100%"
          }
        },
        "0f54382bd8d84aa1a0e2b9efa389ce56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a3e7cc36e3485db1095faeb532f84b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be0eca918d143ec8ee73fdf423439bc",
            "value": 231508
          }
        },
        "90bfc3c14a404c32b4c6a42554eca1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f9f25286df4e808897e7205fcada79",
            "placeholder": "​",
            "style": "IPY_MODEL_07f2ef2cfc224efc8eaeafc5c35c5b69",
            "value": " 232k/232k [00:00&lt;00:00, 436kB/s]"
          }
        },
        "bc4713b3d01f4d58bda699c48c3a8fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e381e29a3c946aaa882ee3d4a6e5349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ae037a5a6414f2e9929490dcf161c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41a3e7cc36e3485db1095faeb532f84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be0eca918d143ec8ee73fdf423439bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9f9f25286df4e808897e7205fcada79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f2ef2cfc224efc8eaeafc5c35c5b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}